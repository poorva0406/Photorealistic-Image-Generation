{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Photorealistic Image Generation Using GANs.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps2IngTZ8i4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe518acc-5431-44c1-d150-fd6bd1e8bdeb"
      },
      "source": [
        "# Clone the official StyleGAN repository from GitHub\n",
        "!git clone https://github.com/NVlabs/stylegan.git"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stylegan'...\n",
            "remote: Enumerating objects: 89, done.\u001b[K\n",
            "remote: Total 89 (delta 0), reused 0 (delta 0), pack-reused 89\u001b[K\n",
            "Unpacking objects: 100% (89/89), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UscKHoh16zo8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a668e589-ae4e-46e8-befa-c9c3f89d76e4"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import PIL.Image\n",
        "import stylegan\n",
        "from stylegan import config\n",
        "from stylegan.dnnlib import tflib\n",
        "from tensorflow.python.util import module_wrapper\n",
        "module_wrapper._PER_MODULE_WARNING_LIMIT = 0\n",
        "\n",
        "# Initialize TensorFlow\n",
        "tflib.init_tf()\n",
        "\n",
        "# Go into that cloned directory\n",
        "path = 'stylegan/'\n",
        "if \"stylegan\" not in os.getcwd():\n",
        "    os.chdir(path)\n",
        "\n",
        "# Load pre-trained network\n",
        "# url = 'https://drive.google.com/uc?id=1MEGjdvVpUsu1jB4zrXZN7Y4kBBOzizDQ' # Downloads the pickled model file: karras2019stylegan-ffhq-1024x1024.pkl\n",
        "url = 'https://bitbucket.org/ezelikman/gans/downloads/karras2019stylegan-ffhq-1024x1024.pkl'\n",
        "with stylegan.dnnlib.util.open_url(url, cache_dir=config.cache_dir) as f:\n",
        "  print(f)\n",
        "  _G, _D, Gs = pickle.load(f)\n",
        "#   Gs.print_layers()  # Print network details"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING: Tensorflow 1 is deprecated, and support will be removed on August 1, 2022.\n",
            "After that, `%tensorflow_version 1.x` will throw an error.\n",
            "\n",
            "Your notebook should be updated to use Tensorflow 2.\n",
            "See the guide at https://www.tensorflow.org/guide/migrate#migrate-from-tensorflow-1x-to-tensorflow-2.\n",
            "\n",
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:34: The name tf.Dimension is deprecated. Please use tf.compat.v1.Dimension instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:74: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/stylegan/dnnlib/tflib/tfutil.py:128: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Downloading https://bitbucket.org/ezelikman/gans/downloads/karras2019stylegan-ffhq-1024x1024.pkl ... done\n",
            "<_io.BytesIO object at 0x7ff15348ad70>\n",
            "WARNING:tensorflow:From <string>:364: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W23SJezZ7l6p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 506
        },
        "outputId": "175ebf28-af6d-416a-c6d1-2b555904adc8"
      },
      "source": [
        "# Set the random seed that generates the noise vectors\n",
        "rnd = np.random.RandomState(40)\n",
        "\n",
        "# Set the number of images to generate\n",
        "batch_size = 3\n",
        "\n",
        "# Set the truncation value for truncation trick sampling\n",
        "truncation = 0.8\n",
        "\n",
        "# Create a noise vector z for each sample in the batch: (batch_size, z_dim)\n",
        "z_dim = Gs.input_shape[1] # StyleGAN authors use the image dim (512) as the size of z\n",
        "print(f'Noise vector has size {z_dim}')\n",
        "noise_vectors = rnd.randn(batch_size, z_dim)\n",
        "\n",
        "# Generate image by running (sampling) the generator\n",
        "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True) # Specify the desired output format and shape\n",
        "images = Gs.run(noise_vectors,\n",
        "                None,    # No labels/conditions because it is unconditional generation (more on this in the coming lectures)\n",
        "                truncation_psi=truncation, \n",
        "                randomize_noise=False,\n",
        "                output_transform=fmt\n",
        "                )\n",
        "\n",
        "# Display images\n",
        "if batch_size > 1:\n",
        "  img = np.concatenate(images, axis=1) # Save all images in batch to a single image\n",
        "else:\n",
        "  img = images[0]\n",
        "PIL.Image.fromarray(img, 'RGB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YOTrHMVfkoI"
      },
      "source": [
        "# Set the random seed that generates the noise vectors\n",
        "rnd = np.random.RandomState(4)\n",
        "\n",
        "# Set the truncation value for truncation trick sampling\n",
        "truncation = 0.7\n",
        "\n",
        "# Set the number of interpolations/number of images to generate\n",
        "n_interpolation = 10\n",
        "\n",
        "# Create a noise vector z for the start and end images (batch_size = 1 since they are single image): (batch_size, z_dim)\n",
        "# And create noise for the interpolations inbetween\n",
        "z_dim = Gs.input_shape[1]\n",
        "first_noise = rnd.randn(1, z_dim)\n",
        "second_noise = rnd.randn(1, z_dim)\n",
        "percent_first_noise = np.linspace(0, 1, n_interpolation)[:, None]\n",
        "interpolation_noise = first_noise * percent_first_noise + second_noise * (1 - percent_first_noise)\n",
        "\n",
        "# Generate image by running (sampling) the generator\n",
        "fmt = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True) # Specify the desired output format and shape\n",
        "images = Gs.run(interpolation_noise,\n",
        "                None,    # No labels/conditions because it is unconditional generation!\n",
        "                truncation_psi=truncation, \n",
        "                randomize_noise=False,\n",
        "                output_transform=fmt\n",
        "                )\n",
        "\n",
        "# Display images\n",
        "if batch_size > 1:\n",
        "  img = np.concatenate(images, axis=1) # Save all images in batch to a single image\n",
        "else:\n",
        "  img = images[0]\n",
        "PIL.Image.fromarray(img, 'RGB')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}